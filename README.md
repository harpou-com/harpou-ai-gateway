# HARPOU AI Gateway
Le cerveau central et l'orchestrateur agentique du Hub Domestique d'IA HARPOU.

1. Vision : Un Agent Autonome pour la Maison
L'AI Gateway n'est pas un simple proxy. C'est le cerveau central du Hub HARPOU. Il agit comme un agent autonome qui op√®re sur un mod√®le fondamentalement asynchrone :

R√©ception & Compr√©hension : Il re√ßoit toutes les requ√™tes de l'interface utilisateur (Open WebUI) et en comprend l'intention profonde.

D√©cision & D√©l√©gation : Il d√©cide d'utiliser un ou plusieurs outils externes (recherche web, contr√¥le domotique, g√©n√©ration d'images, etc.) pour accomplir la t√¢che demand√©e.

Ex√©cution Asynchrone : Il lance l'ex√©cution de ces outils en tant que t√¢ches de fond sans jamais bloquer l'interface, garantissant une exp√©rience utilisateur fluide et r√©active.

Notification Proactive : Il notifie l'utilisateur de mani√®re proactive via WebSockets lorsque les r√©sultats d'une t√¢che longue sont pr√™ts.

Synth√®se & R√©ponse : Il formule une r√©ponse finale coh√©rente en se basant sur les r√©sultats des t√¢ches ex√©cut√©es.

Cette approche garantit que le syst√®me reste r√©actif et scalable, que la t√¢che soit une simple recherche web ou une complexe g√©n√©ration de vid√©o.

2. Architecture d'un Coup d'≈íil
Ce projet est con√ßu pour √™tre modulaire, scalable et robuste, en s'appuyant sur une stack technologique moderne :

Framework Web : Flask & Flask-SocketIO pour le serveur API et la communication temps r√©el.

Traitement Asynchrone : Celery comme moteur de t√¢ches et Redis comme file d'attente (message broker).

Conteneurisation : Docker & Docker Swarm pour le d√©ploiement des services.

Stockage d'Artefacts : MinIO comme solution de stockage objet compatible S3.

Gestion des D√©pendances : PDM pour un environnement Python propre et reproductible.

3. Feuille de Route de D√©veloppement
Le projet √©voluera en suivant les √©tapes cl√©s d√©finies dans notre document d'architecture ma√Ætresse :

‚úÖ √âtape 1 : Fondation Asynchrone

Mise en place de la structure du projet, de Redis, MinIO, Celery et des WebSockets.

Cr√©ation d'un premier flux "ping-pong" pour valider la communication entre tous les composants.

‚è≥ √âtape 2 : Int√©gration des Outils de Base

Int√©gration de la recherche web (SearXNG) et de la lecture de pages web comme des t√¢ches Celery.

üóìÔ∏è √âtape 3 : Ajout des Outils Avanc√©s

Int√©gration du contr√¥le de Home Assistant.

Int√©gration du pilotage de ComfyUI pour la g√©n√©ration d'images.

D√©veloppement de la recherche sur des documents personnels (RAG).

üöÄ √âtape 4 : Vision √† Long Terme

Int√©gration de mod√®les sp√©cialis√©s (vid√©o, 3D, audio) en tant que nouveaux outils.

4. Configuration
La configuration de l'AI Gateway est flexible et peut √™tre g√©r√©e de plusieurs mani√®res, avec la priorit√© suivante :

1.  **Variables d'environnement** : Id√©al pour la production et les d√©ploiements Docker/Swarm. Elles surchargent les valeurs du fichier de configuration.
2.  **Fichier `config/config.json`** : C'est la source de v√©rit√© principale pour la configuration, particuli√®rement pour le d√©veloppement local et la d√©finition de configurations complexes comme les backends multiples.

Un fichier `config/config.example.json` est fourni comme mod√®le.

### Variables d'environnement
Le Gateway peut √™tre enti√®rement configur√© via des variables d'environnement.

> **Note Importante sur la Coh√©rence :** Pour garantir un fonctionnement stable et pr√©visible, il est crucial que tous les services (`web`, `worker`, `beat`) partagent la m√™me configuration. Les variables d'environnement qui d√©finissent des connexions (comme `REDIS_URL`) ou le comportement du backend (`LLM_...`) doivent √™tre appliqu√©es de mani√®re identique √† tous les services dans votre configuration de d√©ploiement (ex: `docker-compose.yml` ou `ai.yml`).


#### Authentification & S√©curit√©

-   **`API_KEY`**: La cl√© API que les clients utiliseront (mode simple).
    -   Peut √™tre une valeur directe ou un chemin vers un fichier secret (ex: `/run/secrets/api_key`).
-   **`API_KEY_RATE_LIMIT`**: (Optionnel) La limite de requ√™tes pour la cl√© unique (ex: `"100/hour"`). Par d√©faut : `"100/hour"`.
-   **`API_KEYS_JSON`**: (Mode avanc√©) Une cha√Æne JSON contenant une liste d'objets de cl√©s. A la priorit√© sur `API_KEY`.
-   **Cl√© secr√®te Flask :**
    -   `FLASK_SECRET_KEY`: Cl√© secr√®te pour signer les sessions.
    -   `FLASK_SECRET_KEY_FILE`: (Recommand√© pour Docker) Chemin vers un fichier contenant la cl√© secr√®te. A la priorit√© sur `FLASK_SECRET_KEY`.

#### Backend LLM (Surcharge en mode simple)

Ces variables permettent de surcharger la configuration `llm_backends` de `config.json` pour d√©finir un unique backend par d√©faut. C'est utile pour des d√©ploiements simples.

-   `LLM_BACKEND_TYPE`: Type de backend (`ollama`, `openai`).
-   `LLM_BASE_URL`: URL de base de l'API du backend.
-   `LLM_DEFAULT_MODEL`: Mod√®le √† utiliser par d√©faut.
-   `LLM_API_KEY`: (Optionnel) Cl√© API pour le backend LLM lui-m√™me.
-   `LLM_AUTO_LOAD`: (Optionnel) `true` pour d√©couvrir automatiquement les mod√®les du backend. Par d√©faut : `false`.

Pour une configuration multi-backends ou de haute disponibilit√©, utilisez le fichier `config.json`.
-   `PRIMARY_BACKEND_NAME`: Nom du backend principal √† utiliser (doit correspondre √† un nom dans `config.json`).
-   `HIGH_AVAILABILITY_STRATEGY`: Strat√©gie de haute disponibilit√© (`none`, `failover`).

#### Services Externes

-   **Celery (T√¢ches asynchrones) :**
    -   `CELERY_BROKER_URL`: URL du broker Redis (ex: `redis://localhost:6379/0`).
    -   `CELERY_RESULT_BACKEND`: URL du backend de r√©sultats Redis (ex: `redis://localhost:6379/0`).
-   **Recherche Web :**
    -   `SEARXNG_BASE_URL`: URL de base de votre instance SearXNG.

#### Journalisation & Performance

-   `LOG_LEVEL`: Niveau de journalisation (`DEBUG`, `INFO`, `WARNING`, `ERROR`). Par d√©faut : `INFO`.
-   `LOG_ROTATION_DAYS`: Nombre de jours de r√©tention des fichiers de log. Par d√©faut : `7`.
-   `LLM_CACHE_MIN_UPDATE`: (Optionnel) Intervalle en minutes pour rafra√Æchir le cache de la liste des mod√®les. Par d√©faut : `5`.
-   `LLM_BACKEND_TIMEOUT`: (Optionnel) D√©lai d'attente en secondes pour les requ√™tes vers les backends LLM. Utile pour les mod√®les lents √† charger. Par d√©faut : `300`.

#### Agent Autonome (Boucle de Raisonnement)

-   `REASONING_LOOP_BUDGET`: Nombre maximum d'it√©rations pour la boucle de raisonnement en mode synchrone. Par d√©faut : `5`.
-   `REASONING_TIME_BUDGET_SECONDS`: Temps maximum en secondes pour la boucle de raisonnement en mode synchrone. Par d√©faut : `45`.
-   `BACKGROUND_LOOP_BUDGET`: Nombre maximum d'it√©rations pour la boucle de raisonnement une fois pass√©e en arri√®re-plan. Par d√©faut : `10`.
-   `FORCE_BACKGROUND_ON_BUDGET_EXCEEDED`: (`true`/`false`) Si `true`, la t√¢che notifiera l'utilisateur et continuera en arri√®re-plan lorsque le budget est √©puis√©. Par d√©faut : `true`.

#### Limitation de D√©bit (Rate Limiting)

-   `RATELIMIT_DEFAULT`: Limite de d√©bit par d√©faut pour les routes non sp√©cifiquement limit√©es (ex: `"200 per day;50 per hour"`).
-   `RATELIMIT_STORAGE_URI`: URI de stockage pour les limites (ex: `redis://localhost:6379/1`).

5. D√©veloppement & D√©ploiement
Le projet suit une approche DevOps avec deux workflows distincts :

D√©veloppement (develop branch) : Utilise un montage de volume (bind mount) et le "hot-reloading" pour une boucle de d√©veloppement ultra-rapide sans reconstruction d'image.

Production (main branch) : S'appuie sur des images Docker immuables construites via un Dockerfile, garantissant la stabilit√© et la reproductibilit√©. Le d√©ploiement est d√©clench√© via une pipeline CI/CD ou une commande √† la demande.

6. Comment Contribuer
Ce projet est actuellement en d√©veloppement actif. Pour toute suggestion ou contribution, veuillez ouvrir une "issue" ou une "pull request".

Ce projet est au c≈ìur du Hub HARPOU, une initiative visant √† cr√©er un √©cosyst√®me d'IA personnel, priv√© et puissant.
